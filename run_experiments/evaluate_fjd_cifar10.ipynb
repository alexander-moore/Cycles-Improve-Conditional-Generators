{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from fjd.fjd_metric import FJDMetric\n",
    "from fjd.embeddings import OneHotEmbedding, InceptionEmbedding\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuspiciouslyGoodGAN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuspiciouslyGoodGAN, self).__init__()\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize(32),\n",
    "            transforms.Normalize(mean=[0.5],\n",
    "                                 std=[0.5])])\n",
    "\n",
    "        test_set = CIFAR10(root='./data',\n",
    "                           train=False,\n",
    "                           download=True,\n",
    "                           transform=transform)\n",
    "\n",
    "        test_loader = DataLoader(test_set,\n",
    "                                 batch_size=128,\n",
    "                                 shuffle=False,\n",
    "                                 drop_last=True)\n",
    "\n",
    "        self.test_loader = test_loader\n",
    "        self.data_iter = iter(test_loader)\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        # Normally a GAN would actually do something with z and y, but for this fake GAN we ignore them\n",
    "        try:\n",
    "            samples, _ = next(self.data_iter)\n",
    "        except StopIteration:\n",
    "            # Reset dataloader if it runs out of samples\n",
    "            self.data_iter = iter(self.test_loader)\n",
    "            samples, _ = next(self.data_iter)\n",
    "        samples = samples.cuda()\n",
    "        return samples\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        ## Decoding:\n",
    "        self.deconv1 = nn.ConvTranspose2d(z_dim, 1024, 4, 1, 0, bias = False) # Not sure how this looks\n",
    "        self.deconv1_bn = nn.BatchNorm2d(1024)\n",
    "        self.deconv2 = nn.ConvTranspose2d(1024, 512, 4, 2, 1, bias = False)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(512)\n",
    "        self.deconv3 = nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(256)\n",
    "        self.deconv4 = nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(128)\n",
    "        #self.deconv5 = nn.ConvTranspose2d(128, 1, 4, 2, 1)\n",
    "        self.deconv5 = nn.ConvTranspose2d(128, 1, 4, 2, 1)\n",
    "    \n",
    "    \n",
    "    def weight_init(self):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m])\n",
    "      \n",
    "    def forward(self, z):\n",
    "        x = self.deconv1_bn(self.deconv1(z))\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        x = torch.tanh(self.deconv5(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_dim = 10\n",
    "v_dim = 100\n",
    "z_dim = 100\n",
    "class InverseAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InverseAutoencoder, self).__init__()\n",
    "        ## Encoding: Unconditional samples\n",
    "        self.conv1 = nn.Conv2d(1, 128, 4, 2, 1) # Input: (bs, 3, img_size, img_size)\n",
    "        self.conv2 = nn.Conv2d(128, 256, 4, 2, 1, bias = False)\n",
    "        self.conv2_bn = nn.BatchNorm2d(256)\n",
    "        self.conv3 = nn.Conv2d(256, 512, 4, 2, 1, bias = False)\n",
    "        self.conv3_bn = nn.BatchNorm2d(512)\n",
    "        self.conv4 = nn.Conv2d(512, 1024, 4, 2, 1, bias = False)\n",
    "        self.conv4_bn = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv5v = nn.Conv2d(1024, v_dim, 4, 1, 0) # Output: (bs, c_dim, 1, 1)\n",
    "        self.conv5c = nn.Conv2d(1024, c_dim, 4, 1, 0) # Output, same as above: but this one to condition-space\n",
    "        \n",
    "        ## Decoding:\n",
    "        self.deconv1v = nn.ConvTranspose2d(v_dim, 1024, 4, 1, 0, bias = False) # Not sure how this looks\n",
    "        self.deconv1c = nn.ConvTranspose2d(c_dim, 1024, 4, 1, 0, bias = False) # Input: (bs, cdim+v_dim, 1, 1)\n",
    "        \n",
    "        self.deconv1_bn = nn.BatchNorm2d(1024)\n",
    "        self.deconv2 = nn.ConvTranspose2d(1024+1024, 512, 4, 2, 1, bias = False)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(512)\n",
    "        self.deconv3 = nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(256)\n",
    "        self.deconv4 = nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(128)\n",
    "        self.deconv5 = nn.ConvTranspose2d(128, 1, 4, 2, 1)\n",
    "    \n",
    "    def weight_init(self):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m])\n",
    "            \n",
    "    def encode(self, x):\n",
    "        # Encode data x to 2 spaces: condition space and variance-space\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        \n",
    "        v = torch.sigmoid(self.conv5v(x)) # Variance-space unif~[0,1]\n",
    "        c = torch.sigmoid(self.conv5c(x)) # this is softmax for CLASSIFICATION. Shapes3d is not 1-classif..\n",
    "        \n",
    "        return v, c\n",
    "      \n",
    "    def forward(self, v, c):\n",
    "        # This is actually conditional generation // decoding.\n",
    "        # It's beneficial to call this forward, though, for FJD calculation\n",
    "        v = self.deconv1_bn(self.deconv1v(v))\n",
    "        c = self.deconv1_bn(self.deconv1c(c))\n",
    "        x = torch.cat((v, c), dim = 1) #stack on channel dim, should be (bs, vdim+cdim, 1, 1). Not sure here\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        x = torch.tanh(self.deconv5(x))\n",
    "        return x\n",
    "    \n",
    "    def pass_thru(self, v, c):\n",
    "        x = self.forward(v, c)\n",
    "        return self.encode(x)\n",
    "  \n",
    "class C_Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C_Generator, self).__init__()\n",
    "        ## Decoding:\n",
    "        self.deconv1v = nn.ConvTranspose2d(v_dim, 1024, 4, 1, 0, bias = False) # Not sure how this looks\n",
    "        self.deconv1c = nn.ConvTranspose2d(c_dim, 1024, 4, 1, 0, bias = False) # Input: (bs, cdim+v_dim, 1, 1)\n",
    "        \n",
    "        self.deconv1_bn = nn.BatchNorm2d(1024)\n",
    "        self.deconv2 = nn.ConvTranspose2d(1024+1024, 512, 4, 2, 1, bias = False)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(512)\n",
    "        self.deconv3 = nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(256)\n",
    "        self.deconv4 = nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(128)\n",
    "        #self.deconv5 = nn.ConvTranspose2d(128, 3, 4, 2, 1)\n",
    "        self.deconv5 = nn.ConvTranspose2d(128, 3, 1, 1, 0)\n",
    "    \n",
    "    \n",
    "    def weight_init(self):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m])\n",
    "      \n",
    "    def forward(self, v, c):\n",
    "        v = self.deconv1_bn(self.deconv1v(v))\n",
    "        c = self.deconv1_bn(self.deconv1c(c))\n",
    "        x = torch.cat((v, c), dim = 1) #stack on channel dim, should be (bs, vdim+cdim, 1, 1). Not sure here\n",
    "        x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
    "        #print('after2', x.shape)\n",
    "        x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
    "        #print('after3', x.shape)\n",
    "        x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
    "        #print('after4', x.shape)\n",
    "        x = torch.tanh(self.deconv5(x))\n",
    "        #print('after5', x.shape)\n",
    "        return x\n",
    "    \n",
    "def one_hot_embedding(labels):\n",
    "    #y = torch.eye(num_classes)\n",
    "    #return y[labels]\n",
    "    #return torch.nn.functional.one_hot(labels)[:,1:]\n",
    "    \n",
    "    labels = torch.nn.functional.one_hot(torch.tensor(labels).to(torch.int64), num_classes = c_dim)\n",
    "    return torch.squeeze(labels)\n",
    "\n",
    "def print_g_sample():\n",
    "    with torch.no_grad():\n",
    "        codes = one_hot_embedding(torch.tensor(list(range(9)), device = device)).view(9,c_dim,1,1).float()\n",
    "        varis = torch.randn((9, v_dim,1,1), device = device) # walk from [0,...,0] to [1,...,1]\n",
    "        generated = .5*(IAE(varis, codes).cpu() + 1)\n",
    "        generated = torch.squeeze(generated)\n",
    "        #print(generated.shape)\n",
    "        for i in range(9):\n",
    "            plt.subplot(330 + 1 + i)\n",
    "            # plot raw pixel data\n",
    "            element = generated[i,:]\n",
    "            plt.imshow(element, cmap = 'gray')\n",
    "        plt.show()\n",
    "        \n",
    "#print_g_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders():\n",
    "    #transform = transforms.Compose(\n",
    "    #    [transforms.ToTensor(),\n",
    "    #     transforms.Normalize(mean=(0.5, 0.5, 0.5), \n",
    "    #                          std=(0.5, 0.5, 0.5))])\n",
    "    \n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Resize(32), #64\n",
    "         transforms.Normalize(mean=[0.5], \n",
    "                              std=[0.5])])\n",
    "\n",
    "    train_set = CIFAR10(root='./data',\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=transform)\n",
    "\n",
    "    test_set = CIFAR10(root='./data',\n",
    "                       train=False,\n",
    "                       download=True,\n",
    "                       transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_set,\n",
    "                              batch_size=128,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True)\n",
    "\n",
    "    test_loader = DataLoader(test_set,\n",
    "                             batch_size=128,\n",
    "                             shuffle=True,\n",
    "                             drop_last=True)\n",
    "    \n",
    "    x = next(iter(train_loader))\n",
    "    print(x[0].shape)\n",
    "    print(x[1].shape)\n",
    "    print(torch.min(x[0]), torch.max(x[0]))\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "#print_g_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## My GANWrapper\n",
    "class GANWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, y):\n",
    "        \n",
    "        y_nat = y\n",
    "        if audit == True:\n",
    "            print(y[0:9])\n",
    "\n",
    "        batch_size = y.size(0)\n",
    "        y = onehot_embedding(y).to(device).view(batch_size, c_dim, 1, 1)\n",
    "\n",
    "        z = torch.randn((batch_size, v_dim, 1, 1), device = device)\n",
    "        \n",
    "        #samples = G(z, y)\n",
    "        samples = self.model(z)\n",
    "        \n",
    "        if audit == True:\n",
    "            for i in range(9):\n",
    "                ind = y_nat[i]\n",
    "                plt.subplot(330 + 1 + i).set_title(str(classes[ind]))\n",
    "                # plot raw pixel data\n",
    "                element = 0.5*(samples[i,:].permute(1,2,0).cpu() + 1)\n",
    "                plt.imshow(element, cmap = 'gray')\n",
    "            plt.show()\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "#print_g_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n",
      "tensor(-1.) tensor(1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to C:\\Users\\Alex/.cache\\torch\\hub\\checkpoints\\inception_v3_google-1a9a5a14.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f916bf5a5b2419d9ea553b44c0ed24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108857766.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audit = False\n",
    "\n",
    "  \n",
    "#IAE = InverseAutoencoder().to(device)\n",
    "#IAE.load_state_dict(torch.load('models/icaegan_mnist_G.pt'))\n",
    "\n",
    "#CG = C_Generator().to(device)\n",
    "#CG.load_state_dict(torch.load('models/cgan_cifar_G.pt'))\n",
    "\n",
    "from supervised.g_arches import rgb_32_G\n",
    "\n",
    "G = rgb_32_G(z_dim).to(device)\n",
    "G.load_state_dict(torch.load('models/gan_cifar_60e_G.pt'))\n",
    "\n",
    "train_loader, test_loader = get_dataloaders()\n",
    "inception_embedding = InceptionEmbedding(parallel=False)\n",
    "onehot_embedding = OneHotEmbedding(num_classes=10)\n",
    "#gan = SuspiciouslyGoodGAN()\n",
    "#gan = InverseAutoencoder()\n",
    "#gan = CG\n",
    "#params = 'models/gan_mnist_G.pt'\n",
    "gan = GANWrapper(G)\n",
    "#gan = GANWrapper(model = gan, model_checkpoint = params)\n",
    "#gan.print_sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fjd_metric = FJDMetric(gan=gan,\n",
    "                       reference_loader=train_loader, #cifar10 train\n",
    "                       condition_loader=test_loader, #cifar10 test\n",
    "                       image_embedding=inception_embedding, #dont change\n",
    "                       condition_embedding=onehot_embedding,\n",
    "                       reference_stats_path='datasets/cifar_train_stats.npz',\n",
    "                       save_reference_stats=True,\n",
    "                       samples_per_condition=10,\n",
    "                       cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Computing generated distribution:   0%|                                                         | 0/78 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reference statistics from datasets/cifar_train_stats.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing generated distribution: 100%|████████████████████████████████████████████████| 78/78 [15:15<00:00, 11.74s/it]\n",
      "Computing generated distribution:  41%|███████████████████▋                            | 32/78 [17:58<25:50, 33.70s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0c5657eb4598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfjd_metric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfjd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfjd_metric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_fjd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FID: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FJD: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfjd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\IAEGAN\\fjd\\fjd_metric.py\u001b[0m in \u001b[0;36mget_fjd\u001b[1;34m(self, alpha, resample)\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_generated_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_generated_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\IAEGAN\\fjd\\fjd_metric.py\u001b[0m in \u001b[0;36m_get_generated_distribution\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                     \u001b[0mimg_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                     \u001b[0mcond_e\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcondition_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\IAEGAN\\fjd\\embeddings.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# Expects to receive a 1D array of numbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0monehot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0monehot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fid = fjd_metric.get_fid()\n",
    "fjd = fjd_metric.get_fjd()\n",
    "print('FID: ', fid)\n",
    "print('FJD: ', fjd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss = nn.BCELoss()\n",
    "#IAE.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(test_loader: DataLoader, model: nn.Module, device):\n",
    "    total = 0\n",
    "    i = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data = data.to(device=device)\n",
    "            labels = onehot_embedding(labels.to(device=device))\n",
    "\n",
    "            v, predictions = IAE.encode(data)\n",
    "            loss = bce_loss(predictions.view(-1, c_dim), labels)\n",
    "            total += loss.data.item()\n",
    "            i+=1\n",
    "            \n",
    "        print(total / i)\n",
    "        \n",
    "check_accuracy(test_loader, IAE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
